\documentclass[11pt]{article}

\usepackage[margin=0.75in]{geometry}

\begin{document}
<<concordance, echo=FALSE>>=
opts_chunk$set(concordance=TRUE)
@

\setlength{\parskip}{1ex}
\setlength{\parindent}{0pt}

\title{STAT 511 Final Project (Initial Sketch)}
\author{Jim Curro, Eric Hare, Alex Shum}
\date{Apr. 15, 2013}

\maketitle

<<LoadLibraries, echo=FALSE, cache=FALSE, message=FALSE>>=
    ## Libraries
    library(rjson)
    library(plyr)
    library(maps)
    library(tm)
    library(ggplot2)
    library(RgoogleMaps)
    library(xtable)
@

\section*{Introduction}
This is a sketch of our results thus far.  We have made progress on our two biggest goals with the dataset.  First, we've conducted an EDA on the data and discovered some interesting things, which is summarised in section two.  Second, we've used a Term Document Matrix to condense the text of the reviews into a manageable format.  We also have fit an initial SVM to the data in order to predict which reviews have at least one useful vote.  These results are summarised in section three.

\section*{Exploratory Data Analysis}

<<DataProcessing, echo=FALSE, cache=TRUE>>=
    processData <- function(json) {
        lines <- readLines(json)
        json.lines <- lapply(1:length(lines), function(x) { fromJSON(lines[x])})
    }
    
    ## Read in json training files
    business.json <- processData("yelp_training_set_business.json")
    checkin.json <- processData("yelp_training_set_checkin.json")
    reviews.json <- processData("yelp_training_set_review.json")
    user.json <- processData("yelp_training_set_user.json")
    
    
    ## Reviews Data
    ## Convert to DF
    reviews.data <- data.frame(matrix(unlist(reviews.json), nrow = length(reviews.json), byrow = TRUE))
    names(reviews.data) <- c("funny", "useful", "cool", names(reviews.json[[1]])[-1])
    ## Fix some of the data types
    reviews.data$useful <- as.numeric(as.character(reviews.data$useful))
    reviews.data$cool <- as.numeric(as.character(reviews.data$cool))
    reviews.data$funny <- as.numeric(as.character(reviews.data$funny))
    
    
    ## Business Data
    ## We need to turn "Categories" into a comma separated string
    for (i in 1:length(business.json)) {
        business.json[[i]]$categories <- paste(business.json[[i]]$categories, collapse = ",")
    }
    business.data.tmp <- data.frame(matrix(unlist(business.json), nrow = length(business.json), byrow = TRUE))
    names(business.data.tmp) <- names(business.json[[1]])[-8]
    
    
    ## Checkin Data
    ##
    for (i in 1:length(checkin.json)) {
        checkins <- sum(unlist(checkin.json[[i]][-(c(length(checkin.json[[i]]), length(checkin.json[[i]]) - 1))]))
        business_id <- checkin.json[[i]]$business_id
        
        checkin.json[[i]] <- list(business_id = business_id, checkins = checkins)
    }
    checkin.data <- data.frame(matrix(unlist(checkin.json), nrow = length(checkin.json), byrow = TRUE))
    names(checkin.data) <- names(checkin.json[[1]])
    
    
    ## User Data
    user.data <- data.frame(matrix(unlist(user.json), nrow = length(user.json), byrow = TRUE))
    names(user.data) <- c("funny", "useful", "cool", names(user.json[[1]])[-1])
    user.data$useful <- as.numeric(as.character(user.data$useful))
    user.data$cool <- as.numeric(as.character(user.data$cool))
    user.data$funny <- as.numeric(as.character(user.data$funny))
    user.data$average_stars <- as.numeric(as.character(user.data$average_stars))
    user.data$review_count <- as.numeric(as.character(user.data$review_count))
    
    ####
    ## Merge Data
    ## Three sets, businesses and users, with reviews linking businesses to users
    ####
    business.data <- merge(business.data.tmp, checkin.data, by = "business_id")
    business.data$checkins <- as.numeric(as.character(business.data$checkins))
    business.data$review_count <- as.numeric(as.character(business.data$review_count))
    business.data$longitude <- as.numeric(as.character(business.data$longitude))
    business.data$stars <- as.numeric(as.character(business.data$stars))
    business.data$stars.f <- factor(business.data$stars)
    business.data$latitude <- as.numeric(as.character(business.data$latitude))
    
    reviews.data$text <- as.character(reviews.data$text)
@

Figure X displays the number of useful votes against the number of cool votes in blue, and the number of useful votes against the number of funny votes in red.  It can be seen that while both cool and funny votes are great predictors of useful votes, the slope is larger for funny.  In other words, we would expect that the reviews with a set number of funny votes would tend to have more useful votes than those with the same set number of cool votes.

<<UsefulFunny, echo=FALSE, out.height='4in', out.width='8in', fig.show='hold'>>=
qplot(cool, useful, data = user.data, colour = I("blue")) + geom_point(aes(x = funny, y = useful), colour = I("red"))
@

Table X shows the top 10 cities by number of checkins in the database.  It also shows the total number of reviews for all businesses in that city, as well as the percentage of reviews over checkins.  It can be seen that for the biggest cities in the database, there is a very uniform number of about .27 reviews per checkin.

<<CityData, echo=FALSE, results='asis'>>=
business.data$full_address <- as.character(business.data$full_address)

business.data$zip <- substring(business.data$full_address, nchar(business.data$full_address) - 5, nchar(business.data$full_address))

city.data = ddply(business.data,.(city),summarize,
  reviews = sum(review_count),
  checkins = sum(checkins))

city.data <- city.data[with(city.data, order(-checkins)), ]

city.data$percentage <- city.data$reviews/city.data$checkins

print(xtable(city.data[1:10,]), include.rownames = FALSE, table.placement = '!h')
@

Figure X shows boxplots of the number of checkins to each business by the average star rating of that business.  It can be observed that businesses with about a four star rating tend to have the most checkins, but five star rating businesses actually have fewer.  This may be either due to the fact that businesses with such a high rating have fewer total reviews, or they are more expensive and less likely to have a high number of customers.

<<CheckinsBoxplot, echo=FALSE, out.height='4in', out.width='8in', fig.show='hold'>>=
qplot(stars.f, log(checkins), data = business.data, geom = "boxplot", colour = stars.f)
@

\section*{TDM}

<<TDMStuff, echo=FALSE, cache=TRUE>>=
    reviews.data$user_id = as.character(reviews.data$user_id)
    reviews.data$review_id = as.character(reviews.data$review_id)
    reviews.data$business_id = as.character(reviews.data$business_id)
    reviews.data$text = as.character(reviews.data$text)
    
    m = list(Content = "text", Heading = "review_id", Author = "user_id", Description = "business_id")
    t <- readTabular(mapping = m)
    corpus <- Corpus(DataframeSource(reviews.data), readerControl = list(reader = t))
    #tdm = TermDocumentMatrix(corpus)
    
    
    c2 = tm_map(corpus, stripWhitespace)
    c2 = tm_map(c2, removePunctuation)
    c2 = tm_map(c2, tolower)
    c2 = tm_map(c2, removeWords, stopwords("english"))
    c2 = tm_map(c2, removeNumbers)
    c2 = tm_map(c2, stemDocument) #needs weka
    inspect(tdm2[1:5,100:105])
    
    tdm2 = TermDocumentMatrix(c2)
    tdm3 = TermDocumentMatrix(c2, control = list(bounds=list(global = c(10,Inf), local = c(1, Inf))))
    inspect(tdm3[120:125,100:105])
    
    dtm = as.DocumentTermMatrix(tdm3)
    
    dimtdm$dimnames$Terms[tdm[,1]$i]
@


\end{document}